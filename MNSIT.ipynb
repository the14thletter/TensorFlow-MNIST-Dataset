{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNSIT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the14thletter/TensorFlow-MNIST-Dataset/blob/master/MNSIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQmA_7MlOUET",
        "colab_type": "text"
      },
      "source": [
        "# **TensorFlow MNIST Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V-THGolOixb",
        "colab_type": "text"
      },
      "source": [
        "**To download and use MNIST Dataset, use the following commands :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bpOJqQQKK72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xl-5TwjKUKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "5c11e04c-b74b-4575-bcc7-03c063794ec8"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 09:41:49.685111 140653243611008 deprecation.py:323] From <ipython-input-2-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0626 09:41:49.687697 140653243611008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0626 09:41:49.689827 140653243611008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0626 09:41:54.814177 140653243611008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0626 09:41:55.125149 140653243611008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0626 09:41:55.128604 140653243611008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0626 09:41:55.225653 140653243611008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-31HOyF_OwJM",
        "colab_type": "text"
      },
      "source": [
        "**Creating a Placeholder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "484QdS2PKa9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "x = tf.placeholder(tf.float32, [None, 784])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qducysPRO6E0",
        "colab_type": "text"
      },
      "source": [
        "**Adding weights and biases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hPGNOJQKihn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfrnWgU7PHXM",
        "colab_type": "text"
      },
      "source": [
        "**Multiplying the Feature Matrix with the weight and adding a bias to it, then running it through a softmax function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02eCSahdKv9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = tf.nn.softmax(tf.matmul(x, W) + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL2l1heEKywR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_ = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBZ-UPCqPk8g",
        "colab_type": "text"
      },
      "source": [
        "**Defining the  cross entropy , which measures how inefficient your predictions are.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGDZB75lK12u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbZvZ7-AP9et",
        "colab_type": "text"
      },
      "source": [
        "**Using  gradient descent with a learning rate of 0.5 , for cost function optimization.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-h_TYiEK5Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWriO3iqQKs2",
        "colab_type": "text"
      },
      "source": [
        " **Starting a session and initializing the variable created earlier.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH0OYd37K8hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbEY0_VNK_Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.global_variables_initializer().run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siuzLqzRQgCu",
        "colab_type": "text"
      },
      "source": [
        "**Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4EOIprnLB1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _ in range(1000):\n",
        "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNrt-WoQxG6",
        "colab_type": "text"
      },
      "source": [
        "**Checking Accuracy With Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgBWdzq-LN9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-xI6x-9LR1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjsU1DFwLUU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92f42d86-e402-4b15-e30b-1642508b5388"
      },
      "source": [
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVRhW2lgLW2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}